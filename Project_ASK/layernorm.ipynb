{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3111cd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T08:08:02.382947Z",
     "start_time": "2022-02-07T08:08:02.376946Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ec57ed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T09:48:45.080375Z",
     "start_time": "2022-02-07T09:48:45.077381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(2, 3, 4, 4)\n",
    "\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a8b306d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T09:49:48.657720Z",
     "start_time": "2022-02-07T09:49:48.348719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 4])\n",
      "tensor([[[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(input.size()[1:]) \n",
    "m1 = nn.LayerNorm(input.size()[1:], elementwise_affine=False)\n",
    "m2 = nn.LayerNorm(input.size()[1:], elementwise_affine=True)\n",
    "\n",
    "boutput1 = m1(input)\n",
    "boutput2 = m2(input)\n",
    "\n",
    "print(boutput1 - boutput2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "808c4faf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-07T10:35:40.413611Z",
     "start_time": "2022-02-07T10:35:38.051473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "Run time: 0.7481091022491455\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "Run time: 0.7409992218017578\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67, 10])\n",
      "torch.Size([5, 67])\n",
      "torch.Size([5, 67])\n",
      "Run time: 0.8589978218078613\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class RNNBaseModel(nn.Module):\n",
    "    def __init__(self, rnn_type, input_size, hidden_size, output_size):\n",
    "        super(RNNBaseModel, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.layerNorm = nn.LayerNorm(input_size, dtype=torch.float64)\n",
    "\n",
    "        self.rnn = getattr(nn, rnn_type)(input_size, hidden_size, num_layers=1,\n",
    "                                         batch_first=True, dtype=torch.float64, bidirectional=True)\n",
    "\n",
    "        self.out = nn.Linear(hidden_size*2, output_size, dtype=torch.float64)\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        inputs = self.layerNorm(inputs)\n",
    "        output, hidden = self.rnn(inputs, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "def fit(rnn_type):\n",
    "    start = time.time()\n",
    "    \n",
    "    inputs = torch.randn(100, 67, 11, dtype=torch.float64)\n",
    "    \n",
    "    input_size = inputs.shape[2]-1\n",
    "    \n",
    "\n",
    "    # model = RNNBaseModel(train_ds[0][0].shape[1], 16, 1)\n",
    "    model = RNNBaseModel(rnn_type, input_size=input_size, hidden_size=input_size * 2, output_size=1)\n",
    "    loss_func = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    epochs = 1\n",
    "    bs = 5\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for bs_start in range(int(inputs.shape[0]/bs)):\n",
    "            X = inputs[bs_start*bs:bs_start*bs+bs, :, :-1]\n",
    "            y = inputs[bs_start*bs:bs_start*bs+bs, :, -1]\n",
    "                        \n",
    "            outputs, hidden = model(X, None)\n",
    "            outputs = outputs.squeeze()\n",
    "\n",
    "            print(X.shape)\n",
    "            print(y.shape)\n",
    "            print(outputs.shape)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_func(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "#         if (epoch + 1) % 10 == 0:\n",
    "#             model.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 acc = torch.zeros(1)\n",
    "#                 for test_X, test_y in test_dl:\n",
    "#                     # test_X = test_X.unsqueeze(0)\n",
    "#                     # print(test_X.shape)\n",
    "#                     outputs, hidden = model(test_X, None)\n",
    "#                     outputs = outputs.squeeze(2)\n",
    "\n",
    "#                     # print(outputs.shape)\n",
    "#                     # print(test_y.shape)\n",
    "\n",
    "#                     loss = loss_func(outputs, test_y)\n",
    "\n",
    "#                     acc += (outputs * test_y > 0).sum() / test_y.shape[1]\n",
    "\n",
    "#                     test_size = len(test_ds)\n",
    "#                     acc = acc / test_size\n",
    "\n",
    "#                     print(f'{epoch + 1}/{epochs}: loss: {loss}, acc: {acc.item()}, test size: {test_size}')\n",
    "\n",
    "    print(f'Run time: {time.time() - start}')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rnn_type_list = [\"RNN\", \"LSTM\", \"GRU\"]\n",
    "\n",
    "    for rnn_type in rnn_type_list:\n",
    "        fit(rnn_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb95d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormLSTMCell(nn.LSTMCell):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super().__init__(input_size, hidden_size, bias)\n",
    "\n",
    "        self.ln_ih = nn.LayerNorm(4 * hidden_size)\n",
    "        self.ln_hh = nn.LayerNorm(4 * hidden_size)\n",
    "        self.ln_ho = nn.LayerNorm(hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        self.check_forward_input(input)\n",
    "        if hidden is None:\n",
    "            hx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
    "            cx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
    "        else:\n",
    "            hx, cx = hidden\n",
    "        self.check_forward_hidden(input, hx, '[0]')\n",
    "        self.check_forward_hidden(input, cx, '[1]')\n",
    "\n",
    "        gates = self.ln_ih(F.linear(input, self.weight_ih, self.bias_ih)) \\\n",
    "                 + self.ln_hh(F.linear(hx, self.weight_hh, self.bias_hh))\n",
    "        i, f, o = gates[:, :(3 * self.hidden_size)].sigmoid().chunk(3, 1)\n",
    "        g = gates[:, (3 * self.hidden_size):].tanh()\n",
    "\n",
    "        cy = (f * cx) + (i * g)\n",
    "        hy = o * self.ln_ho(cy).tanh()\n",
    "        return hy, cy\n",
    "    \n",
    "\n",
    "class LayerNormLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, bias=True, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        self.hidden0 = nn.ModuleList([\n",
    "            LayerNormLSTMCell(input_size=(input_size if layer == 0 else hidden_size * num_directions),\n",
    "                              hidden_size=hidden_size, bias=bias)\n",
    "            for layer in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        if self.bidirectional:\n",
    "            self.hidden1 = nn.ModuleList([\n",
    "                LayerNormLSTMCell(input_size=(input_size if layer == 0 else hidden_size * num_directions),\n",
    "                                  hidden_size=hidden_size, bias=bias)\n",
    "                for layer in range(num_layers)\n",
    "            ])\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        seq_len, batch_size, hidden_size = input.size()  # supports TxNxH only\n",
    "        num_directions = 2 if self.bidirectional else 1\n",
    "        if hidden is None:\n",
    "            hx = input.new_zeros(self.num_layers * num_directions, batch_size, self.hidden_size, requires_grad=False)\n",
    "            cx = input.new_zeros(self.num_layers * num_directions, batch_size, self.hidden_size, requires_grad=False)\n",
    "        else:\n",
    "            hx, cx = hidden\n",
    "\n",
    "        ht = [[None, ] * (self.num_layers * num_directions)] * seq_len\n",
    "        ct = [[None, ] * (self.num_layers * num_directions)] * seq_len\n",
    "\n",
    "        if self.bidirectional:\n",
    "            xs = input\n",
    "            for l, (layer0, layer1) in enumerate(zip(self.hidden0, self.hidden1)):\n",
    "                l0, l1 = 2 * l, 2 * l + 1\n",
    "                h0, c0, h1, c1 = hx[l0], cx[l0], hx[l1], cx[l1]\n",
    "                for t, (x0, x1) in enumerate(zip(xs, reversed(xs))):\n",
    "                    ht[t][l0], ct[t][l0] = layer0(x0, (h0, c0))\n",
    "                    h0, c0 = ht[t][l0], ct[t][l0]\n",
    "                    t = seq_len - 1 - t\n",
    "                    ht[t][l1], ct[t][l1] = layer1(x1, (h1, c1))\n",
    "                    h1, c1 = ht[t][l1], ct[t][l1]\n",
    "                xs = [torch.cat((h[l0], h[l1]), dim=1) for h in ht]\n",
    "            y  = torch.stack(xs)\n",
    "            hy = torch.stack(ht[-1])\n",
    "            cy = torch.stack(ct[-1])\n",
    "        else:\n",
    "            h, c = hx, cx\n",
    "            for t, x in enumerate(input):\n",
    "                for l, layer in enumerate(self.hidden0):\n",
    "                    ht[t][l], ct[t][l] = layer(x, (h[l], c[l]))\n",
    "                    x = ht[t][l]\n",
    "                h, c = ht[t], ct[t]\n",
    "            y  = torch.stack([h[-1] for h in ht])\n",
    "            hy = torch.stack(ht[-1])\n",
    "            cy = torch.stack(ct[-1])\n",
    "\n",
    "        return y, (hy, cy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_ask_server",
   "language": "python",
   "name": "project_ask_server"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
